#!/bin/bash 

#function to check that swift works
check_swift_connection () {
  test=$(rclone about ${storage_server}: 2> /dev/null | wc -l)
  #test=$(swift stat 2> /dev/null | grep -c "Account:")
    
    if [[ $test -lt 1 ]]
    then 
      #if [ -n "$ACTIVE_TOKEN" ]; then
      #   unset OS_AUTH_TOKEN
      #   export OS_AUTH_TOKEN=$(check_atoken)
      #   #echo "New  OS_AUTH_TOKEN = $OS_AUTH_TOKEN"
      #fi
      
    if [[ -n "$OS_PASSWORD" ]]; then 
      if  [[ $silent -eq 0 ]] ; then     
          echo "Updating token"
      fi
      source $allas_conf_path --user $user -k $OS_PROJECT_NAME -f 
    fi
    test=$(swift stat 2> /dev/null | grep -c "Account:")
    if [[ $test -lt 1 ]]
    then 
       echo "No connection to Allas!"
       echo "Please try setting the the connection again."
       exit 1
    else
      echo "swift connection updated"
    fi
  else 
     echo "swift connection OK" 
  fi 
}

#Function to remove the trailing / if it exist
remove_slash_from_ends(){
path_string=$1
if [[ ${path_string:(-1)} == "/" ]]; then
    path_string=${path_string%/}
fi

if [[  ${path_string:0:1} == "/" ]]; then
    tlen=${#path_string}
    path_string=${path_string:1:tlen}
fi

echo $path_string
}



if [[ $# -lt 1 ]]
then
  echo "Please give the name of a directory or file to be uploaded to allas as an argument of this command."
  echo ""
  exit 1
fi

start_time=$(date +%s)

#default user
user="$USER"
compression=1

#read static variables
inst_root="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
#inst_root=$(dirname $(readlink -f $0))


source $inst_root/a_env_conf

#local variables
bucket_name="not_defined"
fixed_bucket=0
tmp_file="not_defined"
print_help=0
os_project_name="$OS_PROJECT_NAME"
input_def=""
mode="swift"
silent=0
tmp_dir="${tmp_root}/a_put_$$_tmp"
vastaus="x"
free_space_check=1
filelist_level=0
cumulative_size=0
override_mode=0

abspath() { old=`pwd`;new=$(dirname "$1");if [ "$new" != "." ]; then cd $new; fi;file=`pwd`/$(basename "$1");cd $old;echo $file; }

#Process command line
while [[ $# -ge 1 ]]
do
  case "$1" in
             '--bucket' | '-b' )
             # query file
                  bucket_name="$2"
                  #Remove the trailing / if it exist
                  bucket_name=$(remove_slash_from_ends $bucket_name)
                  fixed_bucket=1
                  shift
                  shift
                ;;
             '--project' | '-p' )
                  os_project_name=($2)
                  shift
                  shift
                ;;
             '--object' | '-o' )
                  tmp_file="$2"
                  slashcheck=$(echo $tmp_file | grep -c "/")
                  if [[ $slashcheck -gt 0 ]]; then
                     echo "Slash characters (/) are not allowed when object name is defiend with -o option" 
                     echo "If you want to use slash characters to define a pseudo folder path, add that part of"
                     echo "object name to the bucket definition (-b):"
                     echo
                     echo "     a-put -b bucket-name/pseudo/folder/path -o rest-of-object-name "
                     exit 1
                  fi

                  shift
                  shift
                ;;
            '--s3cmd' )
                  mode=("s3cmd")
                  shift
                ;;
             '--compress' | '-c')
                  compression=(1)
                  shift
                ;;              
             '--nc' | '-n' )
                  compression=(0)
                  free_space_check=0
                  shift
                ;;
             '-s' | '--silent' )
                  silent=(1)
                  shift
                ;;
             '-h' | '--help' )
                  print_help=(1)
                  shift
                ;;
             '--user' | '-u' )
                  user=("$2")
                  shift
                  shift
                ;;
             '--tmpdir' | '-t' )
                  tmp_root=("$2")
                  tmp_dir=("${tmp_root}/a_put_$$_tmp")  
                  shift
                  shift
                ;;
              '-x')
                  free_space_check=0
                  shift
                ;;
              '--simple-filelist')
                 filelist_level=1
                 shift
                ;;
              '--skip-filelist')
                 filelist_level=2
                 shift
                ;;
              '--override')
                 override_mode=1
                 shift
                ;;
               '--input-list')
                  list_file=$2
                  if [[ -e $list_file ]];then
                    input_def=("$(cat $list_file)")                
                  else  
                    echo "Import file list $list_file not found"
                    exit 1  
                  fi 
                  shift
                  shift
                ;;
               
             *)
                   input_def=("$input_def $1")
                   shift                       # No more switches
                ;;
    esac
done

if [ $print_help -eq 1 ]; then
cat <<EOF
This tools is used to upload data from the disk environment of Taito and Puhti to 
allas storage environmnet. The basic syntax of the command is:

   a-put directory_or_file

By default this tool performs following operations:

1. Ensures that you have working connection to Allas storage service and 
defines the project that will be used to store the data.

2. In case of directory, the content of the directory is collected into a single file
(using tar command).

3. By default option --compress (-c), is used. This means that the data is compressed using zstdmt command.
   This is the recommended way if you will be using the data only in CSC computing servers. 
   If you plan to use the uploaded dataset in other that Linux servers, where zstdmt compression may not be available,
   you can disable compression with option --nc (-n).

4. The data is uploaded to Allas using rclone command and swift protocol.

The location were data is stored in allas can be defined with options
--bucket (-b) and --object (-o).

The default option is that data that locates in 
  a) $SCRATCH in Puhti is uploaded to bucket:  project_number-puhti-SCRATCH

  b) $PROJAPPL in Puhti is uploaded to bucket:  project_number-puhti-PROJAPPL

  c) $WRKDIR in Taito is uploaded to bucket:  username-project_number-taito-WRKDIR 

  c) in other cases the data uploaded to: username-poject_number-MISC

For example for user kkaytaj belonging in project_12345, data locatioing in home directory
will be uploaded to bucket:  kkayttaj-12345-MISC.

The compressed dataset will be stored as one object. The object name depends on the
file name and location.  The logic used is that the possible subdirectory path in Taito or Puhti is included 
in the object name. E.g. a file called test_1.txt in $WRKDIR can be stored with commands:

   cd $WRKDIR
   a-put test_1.txt

In this case the file is stored to bucket: kkayttaj-12345-taito-WRKDIR
as object: test_1.txt.zst

If you have another file called test_1.txt that locates in directory $WRKDIR/project2/sample3
you can store it with commands:
   
  cd $WRKDIR/project2/sample3
  a-put test_1.txt
  
Or commmands
  cd $WRKDIR
  a-put project2/sample3/test_1.txt

In this case the file is stored to bucket: kkayttaj-12345-taito-WRKDIR
as object:  project2/sample3/test_1.txt.zst

Options

-b, --bucket <bucket_name>  Define a name of the bucket into which the data is uploaded.

-p, --project <project_ID>  Upload data into buckets of the defined project in stead of the currently configured project.

-o, --object <object_name>  Define a name for the new object to be created.

--s3cmd                     Use s3cmd protocol for upoload in stead of swift protocol.

-n, --nc                    Do not compress the data that will be uploaded.

-h, --help                  Print this help.

-t, --tmpdir                Define a direcrory that will be used to store 
                            temporary files of the upload process.

-s, --silent                Less output

-u, --user                  Define username liked to the data to be uploaded

--simple-filelist           Only filenames, not owner, size and date, are collected to the metadatafile.
                            This feature is automatically used for diredtories that contain more than 5000 items.

--skip-filelist             Do not collect information about the files that the object contains to metadata file
                            Using this option speeds up the upload process significantly if the directory 
                            that will be uploaded contains large amount of files. However, a-find can't be used
                            for objects uploaded this way.

--override                  Allow overwriting existing objects.

--input-list                Give a file that lists the files or directtories to be uploaded to Allas.
                            Each item will be stored as one object.

Related commands: a-find, a-get, a-delete, a-info
EOF

exit 

fi 

#Assign project to be used if not defined 



if [[ $os_project_name == "" ]]
then
  if [ -e $HOME/.allas_default ]
  then
     source $HOME/.allas_default
  else
     echo "Default project is not defined"
     source $allas_conf_path -user $user
     echo "os_project_name=$OS_PROJECT_NAME" > $HOME/.allas_default
     echo "Default allas project is stored to  \$HOME/.allas_default"
     echo ""
  fi
  source $HOME/.allas_default
fi


#Check if zstdmt is needed and available
if [[ $compression -eq 1 ]]; then
   if [[ $(which zstdmt 2> /dev/null | wc -l ) -ne 1 ]];then
      echo "Compression command: zstdmt is not available"
      echo "Please install zstdmt or use option --nc:"
      echo "  a-put --nc "
      echo "to skip zstdmt compression during upload."
      exit 1
   fi
fi

#Check if rclone is needed and available
if [[ $mode == "swift" ]]; then
   if [[ $(which rclone 2> /dev/null | wc -l ) -ne 1 ]];then
      echo ""
      echo "rclone is not available!"
      echo "Please install rclone."
      exit 1
   fi
fi

#check free space in $WRKDIR
if [[ $free_space_check -eq 1 ]]; then
  if [[ $(which lfs 2> /dev/null | wc -l ) -eq 1 ]]
  then
    if [[ $local_host == "taito" ]];then
       quota_s=($(lfs quota -q -u $USER $WRKDIR | tail -1 ))
       free_space=$(expr ${quota_s[2]} - ${quota_s[1]})
    fi
    if [[ $local_host == "puhti" || $local_host == "mahti" ]];then
      projnum=$(echo $tmp_root | awk -F "_" '{ print $2}')
      (( lproj = 600000000 + projnum ))
      #  echo "lfs quota -p $lproj $tmp_root"
      #lfs quota -p $lproj $tmp_root
      quota_s=($(lfs quota -p $lproj $tmp_root | tail -1 ))
      free_space=$(expr ${quota_s[1]} - ${quota_s[0]})
    fi
  else
    free_space=$(df $tmp_root | tail -1 | awk '{print $4}')
  fi
else
    free_space=10000000000
fi

if [[ $silent -eq 0 ]] ; then
 echo "Files or directories to be uploaded: $input_def"
fi

#Check if connection works
if [[ $mode == "swift" ]]
then
  if [[ $silent -eq 0 ]] ; then 
      check_swift_connection 
  else 
      check_swift_connection > /dev/null
  fi
fi

mkdir $tmp_dir
printf "%18s %25s %6s %8s %25s\n" "Date" "Name" "Files" "Size(kB)" "Location in allas" >> ${tmp_dir}/upload.log


for input in $input_def
do
  #Check if connection works and update if needed and possible
  if [[ $mode == "swift" ]]
  then
    if [[ $silent -eq 0 ]] ; then 
      check_swift_connection 
    else 
      check_swift_connection > /dev/null
    fi
  fi

  filelist_level_orig=$filelist_level
  if [[ $silent -eq 0 ]] ; then
     echo "Processing: $input"
  fi
  if [[ ! -e $input ]] ; then
    echo "File or directory $input does not exist!"
    exit 1
  fi 

  #Remove the trailing / if it exist
  if [ $(echo -n $input | tail -c 1) == "/" ]
  then
    sl=$(expr ${#input} - 1)
    input=$(echo $input | cut -c 1-$sl)
  fi
 
  #check that file name does not end with _ameta
  if [[ ${input:(-6):6} == "_ameta" ]]; then
    echo "Found a file/directory name which ends with _ameta"
    echo "  $input"
    echo ""
    echo "Please rename this file as it will mix up a the metadata management of a-put"
    exit 1
  fi

  file_path=$(abspath $input)
  if [[ $silent -eq 0 ]] ; then
     echo "Checking total size of $input. Please wait."
  fi
  tot_size=$(du -s $input | cut -f1)
  (( cumulative_size = cumulative_size + tot_size ))
  #echo $tot_size

  #tmp file name. Depends on compression and if file is a directory
  if [  $tmp_file == "not_defined" ]
  then
    if [[ $(file -b "$input" | grep -c directory ) -ne 1 ]]
    then
       if [[ $compression -eq 1 ]]; then
          tmp_file=($(basename "$input" | tr " " "_" )".zst")
       else 
          tmp_file=($(basename "$input" | tr " " "_" ))
       fi
    else
       if [[ $compression -eq 1 ]]; then
          tmp_file=($(basename "$input" | tr " " "_" )".tar.zst")
       else
          tmp_file=($(basename "$input" | tr " " "_" )".tar")
       fi
    fi
    tmp_file=$(remove_slash_from_ends $tmp_file)
  else
   if [[ $(file -b "$input" | grep -c directory ) -ne 1 ]]
   then
       if [[ $compression -eq 1 ]]; then
          if [[ ${tmp_file: -4} != ".zst" ]]; then
               tmp_file="${tmp_file}.zst"
          fi 
       fi
    else
      if [[ ${tmp_file: -8} != ".tar.zst" ]]; then     
          tmp_file="${tmp_file}.tar.zst"
      fi
    tmp_file=$(remove_slash_from_ends $tmp_file)
   fi
  fi

  #Tarkista ollaanko koti vai työhakemistossa ja valitse ämpäri
  #sen perusteella
  project_label=$(echo ${os_project_name} |  sed -e s/"project_"/""/g)
  if [ $bucket_name == "not_defined" ]
  then
     ## Taito
     #Taito home
     bucket_name=("${user}-${project_label}-MISC")
     if [ $(echo $file_path  | cut -c1-14) == "/homeappl/home" ]
     then
        bucket_name=("${user}-${project_label}-${local_host}-HOME")
        partial_path=$(dirname $file_path | sed -e s/"\/homeappl\/home\/$user"/""/g)
     fi
     #Taito wrk
     if [ $(echo $file_path  | cut -c1-5) == "/wrk/" ]
     then
        bucket_name=("${user}-${project_label}-${local_host}-WRKDIR")
        partial_path=$(dirname $file_path | sed -e s/"\/wrk\/$user"/""/g)
     fi

     #Taito proj
     if [ $(echo $file_path  | cut -c1-6) == "/proj/" ]
     then
        bucket_name=("${user}-${project_label}-${local_host}-PROJ")
        partial_path=$(dirname $file_path | sed -e s/"\/proj"/""/g)
     fi

 
     ## Puhti
     # In Puhti we check if puhti-project and Allas project match
     #Puhti scratch
     if [ $(echo $file_path  | cut -c1-8) == "/scratch" ]
     then
        puhti_project=$(echo $file_path/ |awk -F "/" '{print $3}')
        bucket_name=("${project_label}-${local_host}-SCRATCH")
        if [[  $os_project_name  != $puhti_project ]] && [[ $vastaus != "y" ]] ; then
          echo ""
          echo "NOTE: data locates in Scratch area of project: $puhti_project"
          echo "But it will be stored to Allas under project: $os_project_name"
          echo "Bucket to be used is: $bucket_name"
          echo ""
          echo "Is this OK (y/n)?"
          read vastaus
          if [[ $vastaus != "y" ]]; then
             echo "Exiting, data not uploaded."
             exit 0
          fi
        fi
        partial_path=$(dirname $file_path | sed -e s/"\/scratch\/$puhti_project"/""/g)
     fi
     #FMI Puhti scratch
     if [ $(echo $file_path  | cut -c1-12) == "/fmi/scratch" ]
     then
        puhti_project=$(echo $file_path/ |awk -F "/" '{print $4}')
        bucket_name=("${project_label}-${local_host}-SCRATCH")
        if [[  $os_project_name  != $puhti_project ]] && [[ $vastaus != "y" ]] ; then
          echo ""
          echo "NOTE: data locates in Scratch area of project: $puhti_project"
          echo "But it will be stored to Allas under project: $os_project_name"
          echo "Bucket to be used is: $bucket_name"
          echo ""
          echo "Is this OK (y/n)?"
          read vastaus
          if [[ $vastaus != "y" ]]; then
             echo "Exiting, data not uploaded."
             exit 0
          fi
        fi
        partial_path=$(dirname $file_path | sed -e s/"\/fmi\/scratch\/$puhti_project"/""/g)
     fi
     #Puhti projappl
     if [ $(echo $file_path  | cut -c1-9) == "/projappl" ]
     then
        puhti_project=$(echo $file_path/ |awk -F "/" '{print $3}')
        bucket_name=("${project_label}-${local_host}-PROJAPPL")
        if [[  $os_project_name  != $puhti_project ]] && [[ $vastaus != "y" ]] ; then
          echo ""
          echo "NOTE: data locates in ProjAppl area of project: $puhti_project"
          echo "But it will be stored to Allas under project: $os_project_name"
          echo "Bucket to be used is: $bucket_name"
          echo "Is this OK (y/n)?"
          read vastaus
          if [[ $vastaus != "y" ]]; then
             echo "Exiting, data not uploaded."
             exit 0
          fi
        fi
        partial_path=$(dirname $file_path | sed -e s/"\/projappl\/$puhti_project"/""/g)
     fi
     
     #Puhti FMI-projappl
     if [ $(echo $file_path  | cut -c1-13) == "/fmi/projappl" ]
     then
        puhti_project=$(echo $file_path/ |awk -F "/" '{print $4}')
        bucket_name=("${project_label}-${local_host}-PROJAPPL")
        if [[  $os_project_name  != $puhti_project ]] && [[ $vastaus != "y" ]] ; then
          echo ""
          echo "NOTE: data locates in ProjAppl area of project: $puhti_project"
          echo "But it will be stored to Allas under project: $os_project_name"
          echo "Bucket to be used is: $bucket_name"
          echo "Is this OK (y/n)?"
          read vastaus
          if [[ $vastaus != "y" ]]; then
             echo "Exiting, data not uploaded."
             exit 0
          fi
        fi
        partial_path=$(dirname $file_path | sed -e s/"\/fmi\/projappl\/$puhti_project"/""/g)
     fi
     partial_path=$(remove_slash_from_ends $partial_path)
  fi 

  #Check if stored file already exitst
  #echo "rclone ls ${storage_server}:${bucket_name}/${partial_path}/$tmp_file"
  if [[ $mode == "swift" && $override_mode -eq 0 ]]
  then
     if [[ $partial_path == "" ]]; then
      if [[ $(rclone ls ${storage_server}:${bucket_name}/$tmp_file 2> /dev/null | wc -c) -gt 0 ]]
      then
	echo ""
        echo "A file/directory with the same name has already been uploaded into"
        echo "bucket $bucket_name in $storage_server"
        echo ""
        echo "   ${bucket_name}/${tmp_file}  " 
        echo ""
        echo "Remove the old object if you wish to upload a new version of $input to $storage_server."
        echo "You can add option: --override to your command line to if you want to overwrite the object alrady existing in Allas."
        echo "Aternatrively, you can define different bucket name using option --bucket "
        echo "or define different object name with option --object"


        exit 1
      fi
    else
      if [[ $(rclone ls ${storage_server}:${bucket_name}/${partial_path}/$tmp_file 2> /dev/null | wc -c) -gt 0 ]]
      then

	echo ""
        echo "A file/directory with the same name has already been uploaded into"
        echo "bucket $bucket_name in $storage_server"
        echo ""
        echo "   ${bucket_name}/${tmp_file}  " 
        echo ""
        echo "Remove the old object if you wish to upload a new version of $input to $storage_server."
        echo "You can add option: --override to your command line to if you want to overwrite the object alrady existing in Allas."
        echo "Aternatrively, you can define different bucket name using option --bucket "
        echo "or define different object name with option --object"
        exit 1
      fi
    fi
  fi

  if [[ $mode == "s3cmd" &&  $override_mode -eq 0 ]]
  then
    echo "cheking s3cmd"
    if [[ $(s3cmd ls s3://${bucket_name}${partial_path}/$tmp_file 2> /dev/null | wc -l ) > 1 ]]
    then
      echo ""
      echo "A file/directory with the same name has already been uploaded to $storage_server"
      echo ""
      s3cmd ls s3://${bucket_name}/${partial_path}/$tmp_file | grep -v "_ameta" | sed -e s/'s3:\/\/'// 
      echo ""
      echo "Remove the old file if you wish to upload a new version of $input to $storage_server"
      exit 1
    fi
  fi

  #collect and count metadata
  echo "user: $user" >> ${tmp_dir}/${tmp_file}_ameta
  echo "host: $(hostname)" >> ${tmp_dir}/${tmp_file}_ameta
  echo "host_name: $local_host" >> ${tmp_dir}/${tmp_file}_ameta
  echo "input: $input" >> ${tmp_dir}/${tmp_file}_ameta
  echo "original_location: $file_path " >> ${tmp_dir}/${tmp_file}_ameta
  echo "protocol: $mode " >> ${tmp_dir}/${tmp_file}_ameta
  if [[ $compression -eq 1 ]]; then
     echo "compression: zstd" >> ${tmp_dir}/${tmp_file}_ameta
  else
     echo "compression: none" >> ${tmp_dir}/${tmp_file}_ameta 
  fi
  num_files=0

  #initial check of file or directory count
  if [[ $filelist_level -lt 2 ]] ; then 
    num_check=$(find $input | wc -l )
    if [[ $num_check -gt $max_files ]]; then
      echo ""
      echo "Refusing to process the data."
      echo " "
      echo "$input contains $num_check directories or files."
      echo "Collecting information about all these items would take too long time"
      echo ""
      echo "Try uploading subdirectories of $input:"
      echo ""
      echo "  cd $input"
      echo "  a-put * "
      echo " "
      echo "or use option --skip-filelist skip file list collection to metadata" 
      echo "  a-put --skip-filelist * "
      exit 1
    fi


    if [[ $num_check -gt 5000 ]]; then
      echo "$input contains $num_check directories or files."
      echo "For directories that contain over 5000 files, only simplified file name list will be collected to the metadatafile"
      # This definition is problematic as num_check contains nu,ber of both files and directories.
      num_files=$num_check
      filelist_level=1

    fi

    #Detailed data collection only if there is less than 5000 files
    if [[ $filelist_level -eq 0 ]]; then
 
      ((interval =  $num_check / 100 ))
      if [[ $interval -lt 1000 ]];then
         interval=1000
      fi

      d=0

      #For field separator changed to allow spaces in file names
      SAVEIFS=$IFS
      IFS=$(echo -en "\n\b") 
      for f in $(find "$input" |  file -N -f - | awk -F ': ' '{if  ( $2 != "directory") print $1}' )
      do        
        ls -l "$f" >>  ${tmp_dir}/${tmp_file}_ameta
        (( num_files = num_files + 1 ))
        (( d++ ))
        if [[ $d -gt $interval ]]; then
          printf "%s" "."
          d=0
        fi 
      done
      IFS=$SAVEIFS

      if [ $num_files -eq 0 ]
      then
        echo ""
        echo "$input contains no files!"
        echo "This is probably an old directory that has been emptied by the automatic \$WRKDIR cleaning process."
        rm -f ${tmp_dir}/${tmp_file}_ameta
        rmdir ${tmp_dir} 
        exit 1
      fi
    else
      echo "only file names will be collected to the metadata"
    fi
    
  else
      num_files="unknown_number"
      echo "File listing skipped with --skip-filelist option." >> ${tmp_dir}/${tmp_file}_ameta
  fi

  #check if there is enough space for temporary data
  if [[ $tot_size -gt $max_size ]]
  then 
     echo "This file or directory is too big for this tool"
     echo "Total size: ${tot_size}K"
     echo "Please use swift or rclone command to upload the data to allas"
     rm -f ${tmp_dir}/${tmp_file}_ameta
     rmdir ${tmp_dir} 
     exit 1
  fi 
  echo ""

  if [[ $tot_size -gt $free_space ]] && [[ $compression -eq 1 ]]
  then 
    echo "It looks like that there is not enough space for the temporary files."
    echo "$input contains $num_files files or directories that take ${tot_size}K of disk space"
    echo "Available free space is ${free_space}K"
    echo ""
    echo "a-put often fails when it tries to check the available free space in WRKDIR or scratch directories."
    echo "If you are sure that you have enough space in  WRKDIR or scratch, you can skip this check by adding"
    echo "option -x to your a-put command"
    echo ""
    echo "If you don't have enough free space, upload some data from WRKDIR/scratc with using option --nc."
    echo "With --nc option, data is not compressed and thus temporary storage space is not needed." 

    rm -f ${tmp_dir}/${tmp_file}_ameta
    rmdir ${tmp_dir}
    exit 1
  fi

   
  if [[ $silent -eq 0 ]];then
    echo "$input contains $num_files files or directories that take ${tot_size}K of disk space" 
  fi

  #Pakkaaminen
  if [[ $compression -eq 1 ]]; then
     if [[ $(file -b $input | grep -c directory ) -ne 1 ]]
     then
        if [[ $silent -eq 0 ]] ; then
          echo "Compressing $input"
          zstdmt -f -T3 $input -o ${tmp_dir}/$tmp_file 
        else
          zstdmt -f -T3 $input -o ${tmp_dir}/$tmp_file 2> /dev/null
        fi
        if [[ $filelist_level -eq 1 ]]; then      
           ls $input >> ${tmp_dir}/${tmp_file}_ameta
        fi 
     else
        #compress data
        if [[ $silent -eq 0 ]] ; then
           echo "Collecting data from directory $input to archive file: $tmp_file"
           tar -cvf - "$input"  2> >(tee ${tmp_dir}/tar_list  >&2 ) | zstdmt -T2 > ${tmp_dir}/$tmp_file
        else
           tar -cf - "$input"  2> >(tee ${tmp_dir}/tar_list  >&2 ) | zstdmt -T2 > ${tmp_dir}/$tmp_file 2> /dev/null
        fi
        
        if [[ $filelist_level -eq 1 ]]; then      
           grep -v '/$' ${tmp_dir}/tar_list  >> ${tmp_dir}/${tmp_file}_ameta
        fi   
     fi
  else
  # ei pakkaamista
       if [[ $(file -b $input | grep -c directory ) -ne 1 ]]
       # Tiedosto hoituu linkillä
       then
          ln -s ${file_path} ${tmp_dir}/$tmp_file
       else
         #Hakeisto tar-pakettina      
         if [[ $silent -eq 0 ]] ; then
             echo "Collecting data from directory $input to archive file: $tmp_file"
             tar -cvf - "$input"  2> >(tee ${tmp_dir}/tar_list  >&2 )  > ${tmp_dir}/$tmp_file
         else
             tar -cf - "$input"  2> >(tee ${tmp_dir}/tar_list  >&2 )  > ${tmp_dir}/$tmp_file 2> /dev/null
         fi

	 if [[ $filelist_level -eq 1 ]]; then      
             grep -v '/$' ${tmp_dir}/tar_list  >> ${tmp_dir}/${tmp_file}_ameta
	 fi   

       fi
  fi
  
  if [[ $compression -eq 1 ]] ; then
    #tmp file size in KB
    tmp_size=$(du ${tmp_dir}/$tmp_file | awk '{print $1}')
    if [[  $silent -eq 0 ]]; then
       comp_rate=$(echo "scale=2; ${tot_size}/${tmp_size}" | bc )
       echo ""
       echo "Compression ready. Compression rate was: $comp_rate"
       echo ""
    fi
  else
    tmp_size=$tot_size
  fi

  #upload
  if [ $mode == "swift" ]
  then
    #Check if connection works
    test=$(rclone about ${storage_server}: 2> /dev/null | wc -l)
    #test=$(swift stat 2> /dev/null | grep -c "Account:")
    
    if [[ $test -lt 1 ]]
    then 
        #if [ -n "$ACTIVE_TOKEN" ]; then
        #   unset OS_AUTH_TOKEN
        #   export OS_AUTH_TOKEN=$(check_atoken)
        #   #echo "New  OS_AUTH_TOKEN = $OS_AUTH_TOKEN"
        #fi
      
      if [[ -n "$OS_PASSWORD" ]]; then      
         echo "Updateting token"
         source $allas_conf_path -user $user -k $OS_PROJECT_NAME -f 
      fi
      test=$(rclone about ${storage_server}: 2> /dev/null | wc -l)
      #test=$(swift stat 2> /dev/null | grep -c "Account:")
      if [[ $test -lt 1 ]]
      then 
        echo "No connection to Allas!"
        echo "Please try setting the the connection again."
        exit 1
      fi
    fi 

    if [[ $silent -eq 0 ]] ; then
      echo "Uploading data to allas."
    fi
    # echo "rclone copy --progress ./$tmp_file ${storage_server}:${bucket_name}/${partial_path}"
    if [[ $silent -eq 0 ]] ; then
        if [[ $compression -eq 1 ]] ; then
          #echo "rclone copy --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}" 
          rclone copy --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}
          exitcode=$?
          #echo 
        else  
          #rclone copy --progress ${file_path} ${storage_server}:${bucket_name}/${partial_path}
          rclone copy -L --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}
          exitcode=$?
        fi
    else
        if [[ $compression -eq 1 ]] ; then
          rclone copy  ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path} > /dev/null
          exitcode=$?
        else
          rclone copy -L ${file_path} ${storage_server}:${bucket_name}/${partial_path}
          exitcode=$?
        fi    
    fi
   
    
    if [ $exitcode -ne 0 ]; then
       echo $(date +"%d.%m.%y %H:%m:%S") $input $tot_size  $exitcode >> ${tmp_dir}/upload.log
       echo ""
       echo "File upload for $infile failed!"
       echo "Upload summary:"
       cat ${tmp_dir}/upload.log
       rclone deletefile ${storage_server}:${bucket_name}/${partial_path}/$tmp_file
       rm -f ${tmp_dir}/$tmp_file 
       rm -f ${tmp_dir}/${tmp_file}_ameta
       rm -f ${tmp_dir}/upload.log
       rmdir ${tmp_dir}
       exit 1
    else
        printf  "%18s %25s %6s %8s %25s\n" "$(date +"%d.%m.%y %H:%m:%S")" $input $num_files $tot_size "${bucket_name}/${partial_path}" >> ${tmp_dir}/upload.log
    fi

    # rclone md5sums can be calculated only for files that are smaller than 5GB
    if [[ $tmp_size -lt 5000000 ]]
    then
       if [[ $silent -eq 0 ]] ; then
          echo "Confirming upload..."
       fi
       #checksums for local and allas files 
       sum1=$(md5sum ${tmp_dir}/$tmp_file | awk '{print $1}')
       if [[ $partial_path == "" ]] ; then
          allas_path="${storage_server}:${bucket_name}/$tmp_file"
       else
          allas_path="${storage_server}:${bucket_name}/${partial_path}/$tmp_file"
       fi
       allas_path=$(echo "$allas_path" | sed -e s/"\/\/"/"\/"/g)
      
       sum2=$(rclone md5sum "$allas_path" | awk '{print $1}')
       
       #check is cheksums match 
       if [[ "$sum1" != "$sum2" ]]
       then 
         echo "Upload of $input was not successfull!"
         echo "Cleaning the failed upload"
         echo "Upload summary:"
         cat ${tmp_dir}/upload.log
         rclone deletefile "$allas_path"
         rm -f ${tmp_dir}/$tmp_file 
         rm -f ${tmp_dir}/${tmp_file}_ameta
         rm -f ${tmp_dir}/upload.log
         rmdir ${tmp_dir}
         exit 1
       fi
       if [[ $silent -eq 0 ]] ; then
         echo "$input OK"
       fi
    fi
  fi
  if [ $mode == "s3cmd" ]
  then
     if [[ $partial_path == "" ]] ; then
        s3cmd put ${tmp_dir}/$tmp_file s3://${bucket_name}/$tmp_file
     else
        s3cmd put ${tmp_dir}/$tmp_file s3://${bucket_name}/${partial_path}/$tmp_file
     fi
     exitcode=$?
     echo $(date +"%d.%m.%y %H:%m:%S") $input $exitcode >> ${tmp_dir}/upload.log
     if [ $exitcode -ne 0 ]; then
        echo ""
        echo "File upload for $infile failed"
        echo "Upload summary:"
        cat ${tmp_dir}/upload.log
        s3cmd rm s3://${bucket_name}/${partial_path}/$tmp_file
        rm -f ${tmp_dir}/$tmp_file 
        rm -f ${tmp_dir}/${tmp_file}_ameta
        rm -f ${tmp_dir}/upload.log
        rmdir ${tmp_dir}
        exit 1
     fi
  fi

 
  #echo "Remopving temporary file"
  rm -f  ${tmp_dir}/$tmp_file

  #update metadata
  if [[ $silent -eq 0 ]] ; then
    echo ""
    echo "Adding metadata for uploaded $input"
  fi
  #echo "rclone copy ./${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path}"
  if [ $mode == "swift" ]; then
      if [[ $silent -eq 0 ]] ; then
          rclone copy  -L  --progress ${tmp_dir}/${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path}
      else
          rclone copy -L ${tmp_dir}/${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path} > /dev/null
      fi 
  fi
  if [ $mode == "s3cmd" ]; then
      if [[ $partial_path == "" ]] ; then
         s3cmd put -F ${tmp_dir}/${tmp_file}_ameta s3://${bucket_name}/${tmp_file}_ameta
      else
         s3cmd put -F ${tmp_dir}/${tmp_file}_ameta s3://${bucket_name}/${partial_path}/${tmp_file}_ameta
      fi
  fi
  rm -f ${tmp_dir}/${tmp_file}_ameta

  if [[ $silent -eq 0 ]] ; then
    echo ""
    echo "-------------------------------------------------------------------------------"
    if [[ $compression -eq 1 ]]; then
      echo "$num_files files from $input uploaded to bucket $bucket_name in Allas as one compressed file: "
    else
      echo "$input uploaded to bucket $bucket_name in Allas"
    fi
  fi

  if [[ $partial_path == "" ]]; then
     echo "${bucket_name}/$tmp_file"
  else
     echo "${bucket_name}/${partial_path}/$tmp_file"
  fi

  tmp_file=("not_defined")

  if [[ $fixed_bucket -eq 0 ]]; then 
     bucket_name=("not_defined")
  fi
  filelist_level=$filelist_level_orig
done

if [[ $silent -eq 0 ]] ; then
  echo "-----------------------------------------------------------------"
  echo ""
  echo "Upload summary:"
  cat ${tmp_dir}/upload.log | sed -e s/"\/\/"/"\/"/g
  echo "-----------------------------------------------------------------"
  echo OK
fi
rm -f ${tmp_dir}/tar_list
rm -f ${tmp_dir}/upload.log 
rmdir  ${tmp_dir}
end_time=$(date +%s)
(( kesto = end_time - start_time ))
(( nopeus = cumulative_size / kesto ))
(( nopeusmbs = nopeus / 1000 ))




#Execute log creation
message="$0 $(date) $bucket_name  $kesto $cumulative_size ${nopeusmbs}Mb/s"
printf '{"version": "1.1", "host": "%s", "short_message": "utility log", "full_message": "%s", "level": 6, "_user": "%d"}' $(hostname) "$message" $(id -u) >> $allas_log


#If log is a file and not a service then check permissions
if [[ $(ls $allas_log 2> /dev/null | wc -l) -eq 1 ]]; then
  if [[ $(ls -l $allas_log | awk '{print $3}') == $user ]]; then
     chmod a+rwx  $allas_log
  fi
fi
exit 0
