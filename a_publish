#!/bin/bash 


#default user
user=($USER)

#read static variables
inst_root=$(dirname $(readlink -f $0))
source $inst_root/a_env_conf

if [[ $# -lt 1 ]]
then
  echo "Please give the name of a file to be uploaded to allas as an argument of this command."
  echo ""
  exit 1
fi

# local variables
tmp_file=("not_defined")
bucket_name=("not_defined")
print_help=(0)
os_project_name=("none")
input_def=("")
mode=("swift")
tmp_dir=("${tmp_root}/a_put_$$_tmp")
abspath() { old=`pwd`;new=$(dirname "$1");if [ "$new" != "." ]; then cd $new; fi;file=`pwd`/$(basename "$1");cd $old;echo $file; }

#Process command line
while [[ $# -ge 1 ]]
do
  case "$1" in
             '--bucket' | '-b' )
             # query file
                  bucket_name=($2)
                  shift
                  shift
                ;;
             '--project' | '-p' )
                  os_project_name=($2)
                  shift
                  shift
                ;;
             '--os_file' | '-o' )
                  partial_path=$(dirname $2)
                  tmp_file=$(basename $2)
                  shift
                  shift
                ;;
            '--s3cmd' )
                  mode=("s3cmd")
                  shift
                ;;
             '-h' | '--help' )
                  print_help=(1)
                  shift
                ;;
             *)
                   input_def=("$input_def $1")
                   shift                       # No more switches
                ;;
    esac
done

if [ $print_help -eq 1 ]; then
cat <<EOF

a_publish copies a file to Allas into a bucket that can be publicly accessed. Thus, anyone with the address (URL) of the 
uploaded data object can read and download the data with a web browser or tools like wget and curl. 
a_publish works mostly like a_put but there are some differences: 

1) a_publish can upload only files, not directories. 
2) files are not compressed but they uploaded as they are. 
3) the access control of the target bucket is set so that it is available in read-only mode to the internet.

The basic syntax of the command is:

a_publish file_name

By default, the file is uploaded to a bucket username-projectNumber-pub. You can define other bucket names too using option -b
but you should note that this command will make all data in the bucket publicly accessible, 
including data that has been previously uploaded to the bucket.

The public URL to a data object is:

https://object.pouta.csc.fi/username-projectNumber-pub/object_name

An object uploaded with a_publish can be removed from Allas with command a_delete.
EOF

exit 

fi 

#Configure rclone
if [ ! -e $HOME/.config/rclone ]
then 
  mkdir -p  $HOME/.config/rclone
fi
if [ -e $HOME/.config/rclone/rclone.conf ]
then 
   rc_check=$(grep -c $storage_server $HOME/.config/rclone/rclone.conf)
   if [ $rc_check -lt 1 ]
   then
      echo '[pouta]' >>  $HOME/.config/rclone/rclone.conf
      echo 'type = swift'  >>  $HOME/.config/rclone/rclone.conf
      echo 'env_auth = true'   >>  $HOME/.config/rclone/rclone.conf
   fi
else
   echo '[pouta]' >>  $HOME/.config/rclone/rclone.conf
   echo 'type = swift'  >>  $HOME/.config/rclone/rclone.conf
   echo 'env_auth = true'   >>  $HOME/.config/rclone/rclone.conf 
fi

#Assign project to be used if not defined 
if [ $os_project_name == "none" ]
then
  if [ -e $HOME/.allas_default ]
  then
     source $HOME/.allas_default
     if [[ $os_project_name != $OS_PROJECT_NAME ]]
     then 
        echo "Switching allas configuration to use project $os_project_name"
        source $allas_conf_path -user $user $os_project_name
     fi 
  else
     echo "Default project is not defined"
     source $allas_conf_path -user $user
     echo "os_project_name=$OS_PROJECT_NAME" > $HOME/.allas_default
     echo "Default allas project is stored to  \$HOME/.allas_default"
     echo ""
  fi
fi
source $HOME/.allas_default

#Check if connection works
if [[ $mode == "swift" ]]
then
  test=$(swift stat 2> /dev/null | grep -c "Account:")
  if [[ $test -lt 1 ]]
  then 
    echo "No connection to Allas!"
    echo "Please try setting the the connection again."
    exit 1
  fi 
fi

#source /appl/opt/allas_conf
#input=("$1")

#check free space in $WRKDIR
#quota_s=($(lfs quota -q -u $USER $WRKDIR))
#free_space=$(expr ${quota_s[2]} - ${quota_s[1]})

echo "Files to be uploaded: $input_def"

#set default bucket
project_label=$(echo ${os_project_name} |  sed -e s/"project_"/""/g)
if [[ "$bucket_name" == "not_defined" ]]
then
   bucket_name=("${user}-${project_label}-pub")
fi 
echo "Bucket: $bucket_name"


mkdir $tmp_dir

for input in $input_def
do 
  echo "Processing: $input"
  if [ ! -e $input ] ; then
    echo "File: $input does not exist!"
    exit 1
  fi
  
  if [[ $(file -b $input | grep -c directory ) -eq 1 ]]
  then
    echo "This command can only be used to publish files, not directories."
    exit 1
  fi
 
  #check that file name does not end with _ameta
  if [[ ${input:(-5):5} == "_ameta" ]]; then
    echo "Found a file/directoryname which ends with _ameta"
    echo "  $input"
    echo ""
    echo "Please rename this file as it will mix up a the metadata management of a_put"
    exit 1
  fi

  file_path=$(abspath $input)

  echo "Checking total size of $input. Please wait."
  tot_size=$(du -s $input | cut -f1)
  #echo $tot_size

  #tmp file name. Depens on compression and is file is a directory
  if [  $tmp_file == "not_defined" ]
  then
     tmp_file=($(basename $input | tr " " "_" ))
  fi


  #Check if stored file already exitst 
  if [[ $(rclone ls ${storage_server}:${bucket_name}/${partial_path}/$tmp_file 2> /dev/null | wc -c) > 2 ]]
  then
    echo ""
    echo "A file/directory with the same name has already been uploaded into"
    echo "bucket $bucket_name in $storage_server"
    echo ""
    echo "rclone ls ${storage_server}:${bucket_name}${partial_path}/$tmp_file  "
    rclone ls ${storage_server}:${bucket_name}${partial_path}/$tmp_file  
    echo ""
    echo "Remove the old file if you wish to upload a new version of $input to $storage_server."
    echo "Optionally you can define different bucket name using option -bucket ."
    exit 1
  fi

  #collect and count metadata
  echo "user: $user" >> ${tmp_dir}/${tmp_file}_ameta
  echo "host: $(hostname)" >> ${tmp_dir}/${tmp_file}_ameta
  echo "original_location: $file_path" >>  ${tmp_dir}/${tmp_file}_ameta
  echo ""
  ls -l $input >>  ${tmp_dir}/${tmp_file}_ameta
  
  if [[ $tot_size -gt $max_size ]]
  then 
    echo "This file or directory is too big for this tool"
    echo "Total size: ${tot_size}K"
    echo "Please use swift or rclone command to upload the data to allas"
    rm -f ${tmp_dir}/${tmp_file}_ameta
    rmdir ${tmp_dir} 
    exit 1
  fi 

#  if [[ $tot_size -gt $free_space ]]
#  then 
#    echo "There is not enough space for the temporary files."
#    echo "$input contains $num_files files or directories that take ${tot_size}K of disk space"
#    echo "Available free space is ${free_space}K"
#    echo ""
#    rm -f ${tmp_dir}/${tmp_file}_ameta
#    rmdir ${tmp_dir}
#    exit 1
#  fi

  #this is not a good approach.
  #test if a symbolic link would do
  cp $input ${tmp_dir}/$tmp_file  


  #upload

  if [ $mode == "swift" ]
  then
    # For less than 5GB files rclone is used for uploading
    
    echo "Uploading data to allas."
    # echo "rclone copy --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}"
    rclone copy --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}
    exitcode=$?
    if [ $exitcode -ne 0 ]; then
       echo ""
       echo "File upload for $infile failed"
       rclone deletefile ${storage_server}:${bucket_name}/${partial_path}/$tmp_file
       rm -f ${tmp_dir}/$tmp_file 
       rm -f ${tmp_dir}/${tmp_file}_ameta
       rmdir ${tmp_dir}
       exit 1
    fi

    # rclone md5sums can be calculated only for files that are smaller than 5GB
    if [[ $tmp_size -lt 5000000 ]]
    then
       echo "Confirming upload..."
       #checksums for local and allas files 
       sum1=($(md5sum ${tmp_dir}/$tmp_file))
       sum2=($(rclone md5sum  ${storage_server}:${bucket_name}/${partial_path}/$tmp_file))
 
       #check is cheksums match 
       if [[ ${sum1[0]} !=  ${sum2[0]} ]]
       then 
         echo "Upload of $input was not successfull!"
         echo "Cleaning the failed upload"
         rclone deletefile ${storage_server}:${bucket_name}/${partial_path}/$tmp_file
         rm -f ${tmp_dir}/$tmp_file 
         rm -f ${tmp_dir}/${tmp_file}_ameta
         rmdir ${tmp_dir}
         exit 1
       fi
       echo "$input OK"
    fi
  fi


  #echo "Remopving temporary file"
  rm -f  ${tmp_dir}/$tmp_file

  #update metadata
  echo ""
  echo "Adding metadata for uploaded $input"
  #echo "rclone copy ./${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path}" 
  rclone copy  ${tmp_dir}/${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path}
  
  rm -f ${tmp_dir}/${tmp_file}_ameta

  echo "$input uploaded to ${bucket_name}"
  if [[ $partial_path == "" ]]; then 
     echo "Publick link: https://object.pouta.csc.fi/${bucket_name}/$tmp_file"
  else 
     echo "Publick link: https://object.pouta.csc.fi/${buket_name}/${partial_path}/$tmp_file"
  fi
  tmp_file=("not_defined")

done

#Publish and rebuild index file

echo '<html>' >  ${tmp_dir}/index.html
for i in $(swift list $bucket_name | grep -v '_ameta$' )
do 
echo '<li><a href="'$i'">'$i'</a></li>' >> ${tmp_dir}/index.html
done
echo '</html>' >>  ${tmp_dir}/index.html
rclone copy  ${tmp_dir}/index.html ${storage_server}:${bucket_name}/

rm -f   ${tmp_dir}/index.html

#set access control
swift post ${bucket_name} --read-acl ".r:*,.rlistings"

rmdir  ${tmp_dir}
echo ""
echo "Upload ready"
exit 0
