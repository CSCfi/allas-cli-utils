#!/bin/bash 


#default user
user=($USER)

#read static variables
inst_root="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
#inst_root=$(dirname $(readlink -f $0))
source $inst_root/a_env_conf

if [[ $# -lt 1 ]]
then
  echo "Please give the name of a filepto be uploaded to allas as an argument of this command."
  echo ""
  exit 1
fi

# local variables
index_mode="static" #static or dynamic
tmp_file="not_defined"
bucket_name="not_defined"
print_help=0
os_project_name="$OS_PROJECT_NAME"
input_def=""
mode="swift"
tmp_dir="${tmp_root}/a_put_$$_tmp"
abspath() { old=`pwd`;new=$(dirname "$1");if [ "$new" != "." ]; then cd $new; fi;file=`pwd`/$(basename "$1");cd $old;echo $file; }

#Process command line
while [[ $# -ge 1 ]]
do
  case "$1" in
             '--bucket' | '-b' )
             # query file
                  bucket_name=($2)
                  shift
                  shift
                ;;
             '--project' | '-p' )
                  os_project_name=($2)
                  shift
                  shift
                ;;
             '--os_file' | '-o' )
                  partial_path=$(dirname $2)
                  tmp_file=$(basename $2)
                  shift
                  shift
                ;;
            '--s3cmd' )
                  mode=("s3cmd")
                  shift
                ;;

             '--index' | '-i' )
                  index_mode=$2
                  if [[ $index_mode == "static" || $index_mode == "dynamic" ]]; then
                     echo "creating $index_mode index"
                  else
                     echo "Unknown index mode: $index_mode"
                     echo "Sould be: static or dynamic" 
                     exit 1
                  fi
                  shift
                  shift
                ;;
              '--input-list')
                  list_file=$2
                  if [[ -e $list_file ]];then
                    input_def=("$(cat $list_file)")                
                  else  
                    echo "Import file list $list_file not found"
                    exit 1  
                  fi 
                  shift
                  shift
                ;;
             '-h' | '--help' )
                  print_help=(1)
                  shift
                ;;
             *)
                   input_def=("$input_def $1")
                   shift                       # No more switches
                ;;
    esac
done

if [ $print_help -eq 1 ]; then
cat <<EOF

a-publish copies a file to Allas into a bucket that can be publicly accessed. Thus, anyone with the address (URL) of the 
uploaded data object can read and download the data with a web browser or tools like wget and curl. 
a-publish works mostly like a-put but there are some differences: 

1) a-publish can upload only files, not directories. 
2) files are not compressed but they uploaded as they are. 
3) the access control of the target bucket is set so that it is available in read-only mode to the internet.

The basic syntax of the command is:

  a-publish file_name

By default, the file is uploaded to a bucket username-projectNumber-pub. You can define other bucket names too using option -b
but you should note that this command will make all data in the bucket publicly accessible, 
including data that has been previously uploaded to the bucket.

The public URL to a data object is:

https://a3s.fi/username-projectNumber-pub/object_name

An object uploaded with a-publish can be removed from Allas with command a-delete.

a-publish options:

 -b, --bucket       Use the defined bucket in stead of the default bucket name
 -o, --os_file      Define alternative name for the object that will be created  
 -i, --index        (static/dynamic).  By defaul a-publis creates a static index file that 
                    includes the objects that are in the target bucket when the command is executed.
                    With setting --index dynamic the command adds a javascript based index file to the
                    bucket. With this option the index.html page lists the objects that are 
                    available in the bucket in the time when this page is accessed. This dynamic indexing tool can list
                    only up to 1000 files.
 --input-list       List of files to be uploaded.    
 

EOF

exit 

fi 

#Configure rclone
if [ ! -e $HOME/.config/rclone ]
then 
  mkdir -p  $HOME/.config/rclone
fi
if [ -e $HOME/.config/rclone/rclone.conf ]
then 
   rc_check=$(grep -c $storage_server $HOME/.config/rclone/rclone.conf)
   if [ $rc_check -lt 1 ]
   then
      echo '[pouta]' >>  $HOME/.config/rclone/rclone.conf
      echo 'type = swift'  >>  $HOME/.config/rclone/rclone.conf
      echo 'env_auth = true'   >>  $HOME/.config/rclone/rclone.conf
   fi
else
   echo '[pouta]' >>  $HOME/.config/rclone/rclone.conf
   echo 'type = swift'  >>  $HOME/.config/rclone/rclone.conf
   echo 'env_auth = true'   >>  $HOME/.config/rclone/rclone.conf 
fi

#Assign project to be used if not defined 
if [ $os_project_name == "" ]
then
  if [ -e $HOME/.allas_default ]
  then
     source $HOME/.allas_default
  else
     echo "Default project is not defined"
     source $allas_conf_path -user $user
     echo "os_project_name=$OS_PROJECT_NAME" > $HOME/.allas_default
     echo "Default allas project is stored to  \$HOME/.allas_default"
     echo ""
  fi
  source $HOME/.allas_default
fi


#Check if connection works
if [[ $mode == "swift" ]]
then
  test=$(rclone about ${storage_server}: 2> /dev/null | wc -l)
  #test=$(swift stat 2> /dev/null | grep -c "Account:")
  if [[ $test -lt 1 ]]
  then 
    echo "No connection to Allas!"
    echo "Please try setting the the connection again."
    exit 1
  fi 
fi

#source /appl/opt/allas_conf
#input=("$1")

#check free space in $WRKDIR
#quota_s=($(lfs quota -q -u $USER $WRKDIR))
#free_space=$(expr ${quota_s[2]} - ${quota_s[1]})

echo "Files to be uploaded: $input_def"

#set default bucket
project_label=$(echo ${os_project_name} |  sed -e s/"project_"/""/g)
if [[ "$bucket_name" == "not_defined" ]]
then
   bucket_name=("${user}-${project_label}-pub")
fi 
echo "Bucket: $bucket_name"


mkdir $tmp_dir

for input in $input_def
do 
  echo "Processing: $input"
  if [ ! -e $input ] ; then
    echo "File: $input does not exist!"
    exit 1
  fi
  
  if [[ $(file -b $input | grep -c directory ) -eq 1 ]]
  then
    echo "This command can only be used to publish files, not directories."
    exit 1
  fi
 
  #check that file name does not end with _ameta
  if [[ ${input:(-5):5} == "_ameta" ]]; then
    echo "Found a file/directoryname which ends with _ameta"
    echo "  $input"
    echo ""
    echo "Please rename this file as it will mix up a the metadata management of a-put"
    exit 1
  fi

  file_path=$(abspath $input)

  echo "Checking total size of $input. Please wait."
  tot_size=$(du -s $input | cut -f1)
  #echo $tot_size

  #tmp file name. Depens on compression and is file is a directory
  if [  $tmp_file == "not_defined" ]
  then
     tmp_file=($(basename $input | tr " " "_" ))
  fi


  #Check if stored file already exitst 
  if [[ $(rclone ls ${storage_server}:${bucket_name}/${partial_path}/$tmp_file 2> /dev/null | wc -c) -gt 2 ]]
  then
    echo ""
    echo "A file/directory with the same name has already been uploaded into"
    echo "bucket $bucket_name in $storage_server"
    echo ""
    echo "rclone ls ${storage_server}:${bucket_name}${partial_path}/$tmp_file  "
    rclone ls ${storage_server}:${bucket_name}${partial_path}/$tmp_file  
    echo ""
    echo "Remove the old file if you wish to upload a new version of $input to $storage_server."
    echo "Optionally you can define different bucket name using option -bucket ."
    exit 1
  fi

  #collect and count metadata
  echo "user: $user" >> ${tmp_dir}/${tmp_file}_ameta
  echo "host: $(hostname)" >> ${tmp_dir}/${tmp_file}_ameta
  echo "original_location: $file_path" >>  ${tmp_dir}/${tmp_file}_ameta
  echo ""
  ls -l $input >>  ${tmp_dir}/${tmp_file}_ameta
  
  if [[ $tot_size -gt $max_size ]]
  then 
    echo "This file or directory is too big for this tool"
    echo "Total size: ${tot_size}K"
    echo "Please use swift or rclone command to upload the data to allas"
    rm -f ${tmp_dir}/${tmp_file}_ameta
    rmdir ${tmp_dir} 
    exit 1
  fi 

#  if [[ $tot_size -gt $free_space ]]
#  then 
#    echo "There is not enough space for the temporary files."
#    echo "$input contains $num_files files or directories that take ${tot_size}K of disk space"
#    echo "Available free space is ${free_space}K"
#    echo ""
#    rm -f ${tmp_dir}/${tmp_file}_ameta
#    rmdir ${tmp_dir}
#    exit 1
#  fi

  #this is not a good approach.
  #test if a symbolic link would do
  #cp $input ${tmp_dir}/$tmp_file  
  ln -s ${file_path} ${tmp_dir}/$tmp_file

  #upload
  if [ $mode == "swift" ]
  then
    # For less than 5GB files rclone is used for uploading
    
    echo "Uploading data to allas."
    # echo "rclone copy --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}"
    rclone copy -L --progress ${tmp_dir}/$tmp_file ${storage_server}:${bucket_name}/${partial_path}
    exitcode=$?
    if [ $exitcode -ne 0 ]; then
       echo ""
       echo "File upload for $infile failed"
       rclone deletefile ${storage_server}:${bucket_name}/${partial_path}/$tmp_file
       rm -f ${tmp_dir}/$tmp_file 
       rm -f ${tmp_dir}/${tmp_file}_ameta
       rmdir ${tmp_dir}
       exit 1
    fi

   # rclone md5sums can be calculated only for files that are smaller than 5GB
   if [[ $tot_size -lt 5000000 ]]
   then
       echo "Confirming upload..."
       #checksums for local and allas files 
       sum1=($(md5sum ${tmp_dir}/$tmp_file))
       sum2=($(rclone md5sum  ${storage_server}:${bucket_name}/${partial_path}/$tmp_file))
 
       #check if cheksums match 
       if [[ ${sum1[0]} !=  ${sum2[0]} ]]
       then 
         echo "Upload of $input was not successfull!"
         echo "Cleaning the failed upload"
         rclone deletefile ${storage_server}:${bucket_name}/${partial_path}/$tmp_file
         rm -f ${tmp_dir}/$tmp_file 
         rm -f ${tmp_dir}/${tmp_file}_ameta
         rmdir ${tmp_dir}
         exit 1
       fi
       echo "$input OK"
    fi
  fi


  #echo "Remopving temporary file"
  rm -f  ${tmp_dir}/$tmp_file

  #update metadata
  echo ""
  echo "Adding metadata for uploaded $input"
  #echo "rclone copy ./${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path}" 
  rclone copy  ${tmp_dir}/${tmp_file}_ameta ${storage_server}:${bucket_name}/${partial_path}
  
  rm -f ${tmp_dir}/${tmp_file}_ameta

  echo "$input uploaded to ${bucket_name}"
  if [[ $partial_path == "" ]]; then 
     echo "Publick link: https://a3s.fi/${bucket_name}/$tmp_file"
  else 
     echo "Publick link: https://a3s.fi/${buket_name}/${partial_path}/$tmp_file"
  fi
  tmp_file=("not_defined")

done

#Publish and rebuild index file
#Publish and rebuild index file
if [[ $index_mode == "static" ]];then
  echo '<html>' >  ${tmp_dir}/index.html
  echo '<table>' >>  ${tmp_dir}/index.html
  echo "<h2>Contents of bucket $bucket_name<h2>" >>  ${tmp_dir}/index.html
  rclone lsl allas:$bucket_name | grep -v "_ameta" | awk '{print "<tr><td>"$1"</td><td>"$2"</td><td>"$3"</td><td><b><a href=\"https://a3s.fi/'$bucket_name'/"$4"\">"$4"</a></b></td><td><a href=\"https://a3s.fi/'$bucket_name'/"$4"_ameta\" target=\"_self\" >info</a></td></tr>"}' >>  ${tmp_dir}/index.html
  echo '</table>'  >>  ${tmp_dir}/index.html
  echo '</html>' >>  ${tmp_dir}/index.html
else
  wget https://raw.githubusercontent.com/CSCfi/allas-cli-utils/master/dynamic_index.js
  mv dynamic_index.js ${tmp_dir}/index.html
fi


rclone copy  ${tmp_dir}/index.html ${storage_server}:${bucket_name}/
rm -f   ${tmp_dir}/index.html

#set access control
swift post ${bucket_name} --read-acl ".r:*,.rlistings"
swift post "${bucket_name}_segments" --read-acl ".r:*,.rlistings"

rmdir  ${tmp_dir}
echo ""
echo "Upload ready"
exit 0
